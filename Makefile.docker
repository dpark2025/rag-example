.PHONY: build start stop logs shell-rag pull-model health check-ollama clean restart help

# Show help information
help:
	@echo "ğŸ³ Local RAG System - Docker Commands (Alternative)"
	@echo "================================================="
	@echo ""
	@echo "ğŸ“‹ Setup & Management:"
	@echo "  setup           Complete system setup (check-ollama + build + start + model)"
	@echo "  check-ollama    Verify Ollama is installed and running"
	@echo "  build           Build RAG application container with Docker"
	@echo "  start           Start RAG services with Docker (requires Ollama running)"
	@echo "  stop            Stop RAG services"
	@echo "  restart         Clean restart (clean + build + start)"
	@echo "  clean           Remove existing containers for fresh start"
	@echo ""
	@echo "ğŸ“Š Monitoring & Access:" 
	@echo "  health          Check system health status"
	@echo "  logs            View real-time container logs"
	@echo "  shell-rag       Access RAG application container shell"
	@echo ""
	@echo "ğŸ¤– Model Management:"
	@echo "  pull-model      Download Ollama model (usage: make -f Makefile.docker pull-model MODEL=llama3.2:8b)"
	@echo "  list-models     List available Ollama models"
	@echo ""
	@echo "ğŸŒ Access Points:"
	@echo "  Streamlit UI:   http://localhost:8501"
	@echo "  FastAPI Docs:   http://localhost:8000/docs"  
	@echo "  Ollama API:     http://localhost:11434"
	@echo ""
	@echo "ğŸ› ï¸ Troubleshooting:"
	@echo "  ./fix-container-docker.sh          Fix container name conflicts"
	@echo "  make -f Makefile.docker clean && make -f Makefile.docker start    Fresh restart"
	@echo ""
	@echo "ğŸ’¡ Examples:"
	@echo "  make -f Makefile.docker setup                    # Full setup"
	@echo "  make -f Makefile.docker pull-model MODEL=phi3:mini    # Download small model"
	@echo "  make -f Makefile.docker restart                  # Clean restart"
	@echo ""
	@echo "ğŸ”„ For Podman (Default): Use 'make <command>' instead"
	@echo ""

# Check if Ollama is installed and running
check-ollama:
	@echo "ğŸ” Checking Ollama..."
	@command -v ollama >/dev/null 2>&1 || { echo "âŒ Ollama not installed. Visit https://ollama.ai/download"; exit 1; }
	@curl -s http://localhost:11434/api/tags >/dev/null 2>&1 || { echo "âŒ Ollama not running. Run: ollama serve"; exit 1; }
	@echo "âœ… Ollama is installed and running"

# Build RAG container with Docker
build:
	docker-compose -f docker-compose.docker.yml build

# Start the RAG application with Docker
start: check-ollama
	docker-compose -f docker-compose.docker.yml up -d

# Stop the RAG application
stop:
	docker-compose -f docker-compose.docker.yml down

# View logs
logs:
	docker-compose -f docker-compose.docker.yml logs -f

# Shell into RAG app container
shell-rag:
	docker-compose -f docker-compose.docker.yml exec rag-app bash

# Pull a new model (usage: make pull-model MODEL=llama3.2:8b)
pull-model:
	ollama pull $(MODEL)

# List available models
list-models:
	ollama list

# Check system health
health:
	@echo "Checking system health..."
	@curl -s http://localhost:8501/_stcore/health > /dev/null && echo "âœ… RAG App: Healthy" || echo "âŒ RAG App: Unhealthy"
	@curl -s http://localhost:11434/api/tags > /dev/null && echo "âœ… Ollama: Healthy" || echo "âŒ Ollama: Unhealthy"

# Clean up containers and restart fresh
clean:
	@echo "ğŸ§¹ Cleaning up containers..."
	@docker stop local-rag-app 2>/dev/null || true
	@docker rm local-rag-app 2>/dev/null || true
	@docker-compose -f docker-compose.docker.yml down 2>/dev/null || true
	@echo "âœ… Cleanup complete"

# Restart with clean slate
restart: clean check-ollama build start
	@echo "ğŸ”„ System restarted successfully"

# Complete setup
setup: check-ollama build start
	@echo "â³ Waiting for RAG application to be ready..."
	@sleep 10
	@echo "ğŸ“¥ Checking for initial model..."
	@ollama list | grep -q llama3.2:3b || ollama pull llama3.2:3b
	@echo "âœ… Setup complete! Visit http://localhost:8501"